{"cells":[{"cell_type":"markdown","metadata":{"id":"TXeFt4xg6M2M"},"source":["# **Prepara√ß√£o dos Dados**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":73},"id":"3clAHZoZdOB9"},"outputs":[{"name":"stdout","output_type":"stream","text":["üìÅ Fa√ßa o upload do arquivo all-mias.tar.gz (baixe de http://peipa.essex.ac.uk/pix/mias/all-mias.tar.gz)\n"]},{"data":{"text/html":["\n","     \u003cinput type=\"file\" id=\"files-481a0fa6-98e3-4538-93f9-3ed513c10b89\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" /\u003e\n","     \u003coutput id=\"result-481a0fa6-98e3-4538-93f9-3ed513c10b89\"\u003e\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      \u003c/output\u003e\n","      \u003cscript\u003e// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) =\u003e {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable\u003c!Object\u003e} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) =\u003e {\n","    inputElement.addEventListener('change', (e) =\u003e {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) =\u003e {\n","    cancel.onclick = () =\u003e {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) =\u003e {\n","      const reader = new FileReader();\n","      reader.onload = (e) =\u003e {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position \u003c fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","\u003c/script\u003e "],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"ename":"TypeError","evalue":"'NoneType' object is not subscriptable","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-496962782.py\u001b[0m in \u001b[0;36m\u003ccell line: 0\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"üìÅ Fa√ßa o upload do arquivo all-mias.tar.gz (baixe de http://peipa.essex.ac.uk/pix/mias/all-mias.tar.gz)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 6\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Listar os arquivos enviados no diret√≥rio atual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 171\u001b[0;31m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     result = _output.eval_js(\n\u001b[1;32m    173\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n","\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"]}],"source":["import os\n","\n","# Upload do arquivo .tar.gz baixado do link acima\n","from google.colab import files\n","print(\"üìÅ Fa√ßa o upload do arquivo all-mias.tar.gz (baixe de http://peipa.essex.ac.uk/pix/mias/all-mias.tar.gz)\")\n","uploaded = files.upload()\n","\n","# Listar os arquivos enviados no diret√≥rio atual\n","print(\"üìÇ Arquivos dispon√≠veis no /content:\")\n","for file in os.listdir(\"/content\"):\n","    print(\"-\", file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LzDUlztHc-QW"},"outputs":[],"source":["# =====================================================\n","#  IMPORTA√á√ïES INICIAIS\n","# =====================================================\n","import os\n","import tarfile\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from IPython.display import display\n","\n","# =====================================================\n","#  ETAPA 1: EXTRA√á√ÉO E LEITURA DOS DADOS\n","# =====================================================\n","base_path = \"./mini-mias\"\n","os.makedirs(base_path, exist_ok=True)\n","\n","# Renomear o arquivo .tar.gz (caso necess√°rio)\n","for file in os.listdir(\".\"):\n","    if file.endswith(\".tar.gz\"):\n","        os.rename(file, \"all-mias.tar.gz\")\n","        print(f\"‚úÖ Arquivo renomeado: {file} ‚Üí all-mias.tar.gz\")\n","        break\n","\n","# Extrair conte√∫do\n","print(\"üì¶ Extraindo conte√∫do...\")\n","with tarfile.open(\"all-mias.tar.gz\", \"r:gz\") as tar:\n","    tar.extractall(path=base_path)\n","\n","# Listar imagens\n","pgm_files = sorted([f for f in os.listdir(base_path) if f.endswith(\".pgm\")])\n","print(f\"üìÅ Total de imagens encontradas: {len(pgm_files)}\")\n","\n","# Mostrar amostras\n","plt.figure(figsize=(12, 6))\n","for i, file in enumerate(pgm_files[:6]):\n","    img = cv2.imread(os.path.join(base_path, file), cv2.IMREAD_GRAYSCALE)\n","    plt.subplot(2, 3, i + 1)\n","    plt.imshow(img, cmap=\"gray\")\n","    plt.title(file)\n","    plt.axis(\"off\")\n","plt.tight_layout()\n","plt.suptitle(\"üñºÔ∏è Amostras da Base Mini-MIAS\", fontsize=16)\n","plt.show()\n","\n","# Estat√≠sticas das dimens√µes\n","shapes = [cv2.imread(os.path.join(base_path, f), cv2.IMREAD_GRAYSCALE).shape for f in pgm_files]\n","heights, widths = zip(*shapes)\n","print(\"\\nüìä Estat√≠sticas das imagens:\")\n","print(f\"- Dimens√µes √∫nicas: {np.unique(shapes, axis=0)}\")\n","print(f\"- M√©dia altura: {np.mean(heights):.2f}px | M√©dia largura: {np.mean(widths):.2f}px\")\n","\n","# =====================================================\n","#  ETAPA 2: LEITURA DO INFO.TXT\n","# =====================================================\n","info_path = os.path.join(base_path, \"Info.txt\")\n","print(\"\\nüìÑ Lendo Info.txt...\")\n","\n","data = []\n","with open(info_path, \"r\") as f:\n","    for line in f:\n","        line = line.strip()\n","        if not line.startswith(\"mdb\"):\n","            continue\n","\n","        parts = line.split()\n","        filename = parts[0]\n","        tissue = parts[1] if len(parts) \u003e 1 else \"\"\n","        abnormality = parts[2] if len(parts) \u003e 2 else \"\"\n","\n","        severity = \"normal\"\n","        x = y = radius = 0\n","\n","        if len(parts) == 7:\n","            severity = parts[3]\n","            try:\n","                x, y, radius = map(int, parts[4:7])\n","            except:\n","                pass\n","        elif len(parts) == 3:\n","            severity = \"normal\"\n","        else:\n","            severity = parts[3]\n","\n","        data.append([filename, tissue, abnormality, severity, x, y, radius])\n","\n","df_info = pd.DataFrame(data, columns=[\"filename\", \"tissue\", \"abnormality\", \"severity\", \"x\", \"y\", \"radius\"])\n","print(df_info.head())\n","print(f\"\\nTotal de registros processados: {len(df_info)}\")\n","\n","# Estat√≠sticas das classes\n","print(\"\\nüìä Distribui√ß√£o das classes (abnormality):\")\n","print(df_info[\"abnormality\"].value_counts())\n","print(\"\\nüìä Distribui√ß√£o da severidade (severity):\")\n","print(df_info[\"severity\"].value_counts())\n","\n","# Resumo final\n","normais = df_info[df_info[\"abnormality\"].str.upper() == \"NORM\"].shape[0]\n","anormais = df_info[df_info[\"abnormality\"].str.upper() != \"NORM\"].shape[0]\n","total = len(df_info)\n","\n","resumo = pd.DataFrame({\n","    \"Tipo de imagem\": [\"Normais\", \"Com anormalidade\", \"Total\"],\n","    \"Quantidade\": [normais, anormais, total]\n","})\n","print(\"\\nüìã Resumo:\")\n","display(resumo)\n","\n","# =====================================================\n","#  ETAPA 3: PREPARAR LABELS\n","# =====================================================\n","df_labels = df_info.copy()\n","class_map = {\"normal\": 0, \"B\": 1, \"M\": 1}  # bin√°rio: normal vs anormal\n","df_labels[\"label\"] = df_labels[\"severity\"].map(class_map)\n","df_labels[\"filename\"] = df_labels[\"filename\"].apply(lambda f: f if f.endswith(\".pgm\") else f + \".pgm\")\n","\n","print(df_labels[[\"filename\", \"severity\", \"label\"]].head())"]},{"cell_type":"markdown","metadata":{"id":"-bzcaM5FBEIm"},"source":["# **Resnet18**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FxZm6BMa6q71"},"outputs":[],"source":["# =====================================================\n","#  ETAPA 4: RESNET18 SEM PR√â-PROCESSAMENTO\n","# =====================================================\n","!pip install -q tqdm torchvision torchmetrics\n","\n","import torch\n","from torch import nn, optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n","from tqdm import tqdm\n","import os, cv2, numpy as np\n","from sklearn.metrics import classification_report\n","import torchvision.models as models\n","\n","# =====================================================\n","#  DATASET\n","# =====================================================\n","class MiniMIASDataset(Dataset):\n","    def __init__(self, df, base_path):\n","        self.df = df\n","        self.base_path = base_path\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        img_path = os.path.join(self.base_path, row[\"filename\"])\n","        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","        image = cv2.resize(image, (224, 224))\n","\n","        # Converter para tensor normalizado\n","        image = np.expand_dims(image, axis=0)  # [1, H, W]\n","        image = torch.tensor(image, dtype=torch.float32) / 255.0\n","        image = (image - 0.5) / 0.5  # normaliza√ß√£o [-1, 1]\n","\n","        label = torch.tensor(row[\"label\"], dtype=torch.long)\n","        return image, label\n","\n","# =====================================================\n","#  DIVIS√ÉO TREINO/TESTE\n","# =====================================================\n","df_train = df_labels.sample(frac=0.8, random_state=42)\n","df_test = df_labels.drop(df_train.index)\n","\n","dataset_train = MiniMIASDataset(df_train, base_path)\n","dataset_test = MiniMIASDataset(df_test, base_path)\n","\n","# =====================================================\n","#  BALANCEAMENTO\n","# =====================================================\n","class_counts = df_train['label'].value_counts().sort_index()\n","weights_per_class = 1.0 / class_counts\n","sample_weights = df_train['label'].map(weights_per_class).values\n","\n","sampler = WeightedRandomSampler(\n","    weights=sample_weights,\n","    num_samples=len(sample_weights),\n","    replacement=True\n",")\n","\n","dataloader_train = DataLoader(dataset_train, batch_size=16, sampler=sampler)\n","dataloader_test = DataLoader(dataset_test, batch_size=16, shuffle=False)\n","\n","# =====================================================\n","#  MODELO: RESNET18\n","# =====================================================\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"\\nTreinando na device: {device}\")\n","\n","# Carrega ResNet18 pr√©-treinada no ImageNet\n","model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n","\n","# Ajusta primeira camada para 1 canal\n","model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","\n","# Ajusta √∫ltima camada para 2 classes\n","num_features = model.fc.in_features\n","model.fc = nn.Linear(num_features, 2)\n","\n","model = model.to(device)\n","\n","# =====================================================\n","#  TREINAMENTO\n","# =====================================================\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","num_epochs = 30\n","\n","for epoch in range(num_epochs):\n","    print(f\"\\nEpoch [{epoch+1}/{num_epochs}]\")\n","    model.train()\n","    running_loss = 0.0\n","\n","    for data, targets in tqdm(dataloader_train):\n","        data, targets = data.to(device), targets.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(data)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","\n","    print(f\"Loss m√©dio: {running_loss/len(dataloader_train):.4f}\")\n","\n","print(\"\\nTreinamento conclu√≠do.\")\n","\n","# =====================================================\n","#  AVALIA√á√ÉO\n","# =====================================================\n","model.eval()\n","correct, total = 0, 0\n","y_true, y_pred = [], []\n","\n","with torch.no_grad():\n","    for images, labels in dataloader_test:\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model(images)\n","        _, preds = torch.max(outputs, 1)\n","        correct += (preds == labels).sum().item()\n","        total += labels.size(0)\n","        y_true.extend(labels.cpu().numpy())\n","        y_pred.extend(preds.cpu().numpy())\n","\n","test_accuracy = correct / total\n","print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")\n","\n","print(\"\\nüìä Relat√≥rio de Classifica√ß√£o:\")\n","print(classification_report(y_true, y_pred, target_names=[\"Normal\", \"Anormal\"]))\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPLO3NW6GjUfEvVVd3xcN2N","gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}